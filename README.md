# Experiment Overview
https://docs.google.com/document/d/1dINeujuenj3vVN7CHoo9zco3psknCV6OHU6NEHZTJFA/edit?usp=sharing 

The experiment aimed to investigate whether including demographic information—specifically gender—in the training data of a machine learning model impacts its ability to predict student final grades. In doing so, it explores issues of bias and fairness in AI, questioning if such data is necessary for accurate predictions and highlighting the ethical implications of incorporating demographic factors in algorithmic decision-making.

***When I independently conducted this experiment, it was one of my first introductions to machine learning and research. 
Since then, I have worked with more complex machine learning tools and larger codebases in labs. Below are my learnings and takeaways from when I conducted this experiment.***

# Takeaways (Strengths + Weaknesses)

**Structured Experimentation**: Despite my limited background at the time, I designed a clear and structured experiment with well-defined independent and dependent variables, controls, and reproducibility.

**Self-Learning**: The project pushed me to self-learn important machine learning tools and techniques, reinforcing my technical skills and passion for research.

**Robust Testing**: Iteratively training the model 200 times added robustness to my analysis and underscored the importance of thorough testing in experimental design.

**Ethical Inquiry**: Delving into ethical questions about bias in AI has had a lasting impact, guiding my continued interest in the intersection of social justice and technology. 

**Limited Scope**: Testing only one demographic factor—gender—restricted the scope of my findings. Exploring additional variables, like race or socioeconomic status, could have offered deeper insights into bias.

**Model Simplicity**: Relying solely on a simple linear regression model might have constrained my ability to capture more nuanced patterns. More complex models could yield a better understanding of bias.

**Dataset and Validation**: The relatively small dataset and the absence of advanced cross-validation methods may have affected the statistical significance and reliability of the results.

**Lack of Mentorship**: Working largely in isolation without external mentorship limited my access to broader feedback, which might have enriched the project's depth.







